{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Concerts - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen how to scrape a simple website, it's time to again practice those skills on a full-fledged site!\n",
    "\n",
    "In this lab, you'll practice your scraping skills on an online music magazine and events website called Resident Advisor.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Create a full scraping pipeline that involves traversing over many pages of a website, dealing with errors and storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Website\n",
    "\n",
    "For this lab, you'll be scraping the https://ra.co website. For reproducibility we will use the [Internet Archive](https://archive.org/) Wayback Machine to retrieve a version of this page from March 2019.\n",
    "\n",
    "Start by navigating to the events page [here](https://web.archive.org/web/20210325230938/https://ra.co/events/us/newyork?week=2019-03-30) in your browser. It should look something like this:\n",
    "\n",
    "<img src=\"images/ra_top.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Inspect Element Feature\n",
    "\n",
    "Next, open the inspect element feature from your web browser in order to preview the underlying HTML associated with the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Scrape all of the Events on the Given Page\n",
    "\n",
    "The function should return a Pandas DataFrame with columns for the `Event_Name`, `Venue`, and `Number_of_Attendees`.\n",
    "\n",
    "Start by importing the relevant libraries, making a request to the relevant URL, and exploring the contents of the response with `BeautifulSoup`. Then fill in the `scrape_events` function with the relevant code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENTS_PAGE_URL = \"https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-03-30\"\n",
    "\n",
    "# Exploration: making the request and parsing the response\n",
    "html_page = requests.get(EVENTS_PAGE_URL)\n",
    "\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "̸Sat, 30 MarUnterMania IIMary Yuzovskaya, Manni Dee, Umfang, Juana, The Lady MachineTBA - New YorkRARA Tickets457Cocoon New York: Sven Väth, Ilario Alicante, Butch & TaimurSven Vath, Butch, Taimur, Il\n",
      "\n",
      "Sun, 31 MarSunday: Soul SummitNowadaysRARA Tickets132New Dad & Aaron Clark (Honcho)Aaron Clark, New DadAce Hotel3ParadiscoOccupy The DiscoLe Bain3Sunday Soiree: Unknown Showcase (Detroit)Ryan Dahl, Ha\n"
     ]
    }
   ],
   "source": [
    "# Find the container with event listings in it\n",
    "events_all_div = soup.find('div', attrs={\"data-tracking-id\": \"events-all\"})\n",
    "\n",
    "event_listings = events_all_div.find(\"ul\").find(\"li\")\n",
    "print(event_listings.text[:200])\n",
    "print()\n",
    "march_31st_start = event_listings.text.find(\"Sun, 31 Mar\")\n",
    "print(event_listings.text[march_31st_start:march_31st_start + 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 index: ̸Sat, 30 MarUnterMania IIMary Yuzovskaya, Manni Dee, Umfang, Juana, The Lady MachineTBA - New YorkRARA Tickets457Cocoon New York: Sven Väth, Ilario Alicante, Butch & TaimurSven Vath, Butch, Taimur, Il\n",
      "\n",
      "1 index:  \n",
      "\n",
      "2 index: ̸Sun, 31 MarSunday: Soul SummitNowadaysRARA Tickets132New Dad & Aaron Clark (Honcho)Aaron Clark, New DadAce Hotel3ParadiscoOccupy The DiscoLe Bain3Sunday Soiree: Unknown Showcase (Detroit)Ryan Dahl, H\n"
     ]
    }
   ],
   "source": [
    "# Find a list of events by date within that container\n",
    "dates = event_listings.findChildren(recursive=False)\n",
    "# March 30th is at the 0 index\n",
    "print(\"0 index:\", dates[0].text[:200])\n",
    "print()\n",
    "# The 1 index is empty. We'll need to skip this later\n",
    "print(\"1 index: \", dates[1].text)\n",
    "print()\n",
    "# March 31st is at the 2 index\n",
    "print(\"2 index:\", dates[2].text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat, 30 Mar'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the date (e.g. Sat, 30 Mar) from one of those containers\n",
    "# Grabbing just one to practice on\n",
    "first_date = dates[0]\n",
    "# The div with the date happens to have another human-readable\n",
    "# CSS class, so let's use that to select it then grab its text\n",
    "date = first_date.find(\"div\", class_=\"sticky-header\").text\n",
    "# There is a / thing used for aesthetic reasons; let's remove it\n",
    "date = date.strip(\"'̸\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: UnterMania II\n",
      "Venue: TBA - New York\n",
      "Date: Sat, 30 Mar\n",
      "Number of attendees: 457\n"
     ]
    }
   ],
   "source": [
    "# Extract the name, venue, and number of attendees from one of the\n",
    "# events within that container\n",
    "# As noted previously, the div with information about events on\n",
    "# this date contains several ul tags, each with information about\n",
    "# a specific event. Get a list of them.\n",
    "# (Again this is an odd use of HTML, to have an unordered list\n",
    "# containing a single list item. But we scrape what we find!)\n",
    "first_date_events = first_date.findChildren(\"ul\")\n",
    "# Grabbing the first event ul to practice on\n",
    "first_event = first_date_events[0]\n",
    "# Each event ul contains a single h3 with the event name, easy enough\n",
    "name = first_event.find(\"h3\").text\n",
    "# First, get all 1-3 divs that match this description\n",
    "venue_and_attendees = first_event.findAll(\"div\", attrs={\"height\": 30})\n",
    "# The venue is the 0th (left-most) div, get its text\n",
    "venue = venue_and_attendees[0].text\n",
    "# The number of attendees is the last div (although it's sometimes\n",
    "# missing), get its text\n",
    "num_attendees = int(venue_and_attendees[-1].text)\n",
    "# Print out everything for one event\n",
    "print(\"Name:\", name)\n",
    "print(\"Venue:\", venue)\n",
    "print(\"Date:\", date)\n",
    "print(\"Number of attendees:\", num_attendees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnterMania II</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocoon New York: Sven Väth, Ilario Alicante, B...</td>\n",
       "      <td>99 Scott Ave</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horse Meat Disco - New York Residency</td>\n",
       "      <td>Elsewhere</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rave: Underground Resistance All Night</td>\n",
       "      <td>Nowadays</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>A Night at the Baths</td>\n",
       "      <td>C'mon Everybody</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Blaqk Audio</td>\n",
       "      <td>Music Hall of Williamsburg</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Erik the Lover</td>\n",
       "      <td>Erv's</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Wax On Vissions</td>\n",
       "      <td>Starliner</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n",
       "      <td>Schimanski</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0                                        UnterMania II   \n",
       "1    Cocoon New York: Sven Väth, Ilario Alicante, B...   \n",
       "2                Horse Meat Disco - New York Residency   \n",
       "3               Rave: Underground Resistance All Night   \n",
       "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n",
       "..                                                 ...   \n",
       "114                               A Night at the Baths   \n",
       "115                                        Blaqk Audio   \n",
       "116                                     Erik the Lover   \n",
       "117                                    Wax On Vissions   \n",
       "118            Schimanski & Good Looks present: Mercer   \n",
       "\n",
       "                              1            2      3  \n",
       "0                TBA - New York  Sat, 30 Mar  457.0  \n",
       "1                  99 Scott Ave  Sat, 30 Mar  407.0  \n",
       "2                     Elsewhere  Sat, 30 Mar  375.0  \n",
       "3                      Nowadays  Sat, 30 Mar  232.0  \n",
       "4                TBA - New York  Sat, 30 Mar   89.0  \n",
       "..                          ...          ...    ...  \n",
       "114             C'mon Everybody   Fri, 5 Apr    1.0  \n",
       "115  Music Hall of Williamsburg   Fri, 5 Apr    1.0  \n",
       "116                       Erv's   Fri, 5 Apr    1.0  \n",
       "117                   Starliner   Fri, 5 Apr    1.0  \n",
       "118                  Schimanski   Fri, 5 Apr    1.0  \n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over all of the event entries, extract this inform\n",
    "# Create an empty list to hold results\n",
    "rows = []\n",
    "\n",
    "# Loop over all date containers on the page\n",
    "for date_container in dates:\n",
    "    \n",
    "    # First check if this is one of the empty divs. If it is,\n",
    "    # skip ahead to the next one\n",
    "    if not date_container.text:\n",
    "        continue\n",
    "    \n",
    "    # Same logic as above to extract the date\n",
    "    date = date_container.find(\"div\", class_=\"sticky-header\").text\n",
    "    date = date.strip(\"'̸\")\n",
    "    \n",
    "    # This time, loop over all of the events\n",
    "    events = date_container.findChildren(\"ul\")\n",
    "    for event in events:\n",
    "        \n",
    "        # Same logic as above to extract the name, venue, attendees\n",
    "        name = event.find(\"h3\").text\n",
    "        venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n",
    "        venue = venue_and_attendees[0].text\n",
    "        try:\n",
    "            num_attendees = int(venue_and_attendees[-1].text)\n",
    "        except ValueError:\n",
    "            num_attendees = np.nan\n",
    "            \n",
    "        # New piece here: appending the new information to rows list\n",
    "        rows.append([name, venue, date, num_attendees])\n",
    "\n",
    "# Make the list of lists into a dataframe and display\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring it all together in a function that makes the request, gets the\n",
    "# list of entries from the response, loops over that list to extract the\n",
    "# name, venue, date, and number of attendees for each event, and returns\n",
    "# that list of events as a dataframe\n",
    "\n",
    "def scrape_events(events_page_url):\n",
    "    # Make the request and parse the response as HTML\n",
    "    response = requests.get(events_page_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find the container with the relevant content\n",
    "    events_all_div = soup.find('div', attrs={\"data-tracking-id\": \"events-all\"})\n",
    "    event_listings = events_all_div.find(\"ul\").find(\"li\")\n",
    "    dates = event_listings.findChildren(recursive=False)\n",
    "    \n",
    "    # Loop over all dates, an all events on each date, and\n",
    "    # add them to the list\n",
    "    rows = []\n",
    "    for date_container in dates:\n",
    "        \n",
    "        if not date_container.text:\n",
    "            continue\n",
    "\n",
    "        date = date_container.find(\"div\", class_=\"sticky-header\").text\n",
    "        date = date.strip(\"'̸\")\n",
    "\n",
    "        events = date_container.findChildren(\"ul\")\n",
    "        for event in events:\n",
    "            \n",
    "            name = event.find(\"h3\").text\n",
    "            venue_and_attendees = event.findAll(\"div\", attrs={\"height\": 30})\n",
    "            venue = venue_and_attendees[0].text\n",
    "            try:\n",
    "                num_attendees = int(venue_and_attendees[-1].text)\n",
    "            except ValueError:\n",
    "                num_attendees = np.nan\n",
    "\n",
    "            rows.append([name, venue, date, num_attendees])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # This time also specify the column names\n",
    "    df.columns = [\"Event_Name\", \"Venue\", \"Event_Date\", \"Number_of_Attendees\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Number_of_Attendees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnterMania II</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocoon New York: Sven Väth, Ilario Alicante, B...</td>\n",
       "      <td>99 Scott Ave</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horse Meat Disco - New York Residency</td>\n",
       "      <td>Elsewhere</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rave: Underground Resistance All Night</td>\n",
       "      <td>Nowadays</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Believe You Me // Beta Librae, Stephan Kimbel,...</td>\n",
       "      <td>TBA - New York</td>\n",
       "      <td>Sat, 30 Mar</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>A Night at the Baths</td>\n",
       "      <td>C'mon Everybody</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Blaqk Audio</td>\n",
       "      <td>Music Hall of Williamsburg</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Erik the Lover</td>\n",
       "      <td>Erv's</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Wax On Vissions</td>\n",
       "      <td>Starliner</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Schimanski &amp; Good Looks present: Mercer</td>\n",
       "      <td>Schimanski</td>\n",
       "      <td>Fri, 5 Apr</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Event_Name  \\\n",
       "0                                        UnterMania II   \n",
       "1    Cocoon New York: Sven Väth, Ilario Alicante, B...   \n",
       "2                Horse Meat Disco - New York Residency   \n",
       "3               Rave: Underground Resistance All Night   \n",
       "4    Believe You Me // Beta Librae, Stephan Kimbel,...   \n",
       "..                                                 ...   \n",
       "114                               A Night at the Baths   \n",
       "115                                        Blaqk Audio   \n",
       "116                                     Erik the Lover   \n",
       "117                                    Wax On Vissions   \n",
       "118            Schimanski & Good Looks present: Mercer   \n",
       "\n",
       "                          Venue   Event_Date  Number_of_Attendees  \n",
       "0                TBA - New York  Sat, 30 Mar                457.0  \n",
       "1                  99 Scott Ave  Sat, 30 Mar                407.0  \n",
       "2                     Elsewhere  Sat, 30 Mar                375.0  \n",
       "3                      Nowadays  Sat, 30 Mar                232.0  \n",
       "4                TBA - New York  Sat, 30 Mar                 89.0  \n",
       "..                          ...          ...                  ...  \n",
       "114             C'mon Everybody   Fri, 5 Apr                  1.0  \n",
       "115  Music Hall of Williamsburg   Fri, 5 Apr                  1.0  \n",
       "116                       Erv's   Fri, 5 Apr                  1.0  \n",
       "117                   Starliner   Fri, 5 Apr                  1.0  \n",
       "118                  Schimanski   Fri, 5 Apr                  1.0  \n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out your function\n",
    "scrape_events(EVENTS_PAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Retrieve the URL for the Next Page\n",
    "\n",
    "As you scroll down, there should be a button labeled \"Next Week\" that will take you to the next page of events. Write code to find that button and extract the URL from it.\n",
    "\n",
    "This is a relative path, so make sure you add `https://web.archive.org` to the front to get the URL.\n",
    "\n",
    "![next page](images/ra_next.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the button, find the relative path, create the URL for the current `soup`\n",
    "# This is tricky again, since there are not a lot of\n",
    "# human-readable CSS classes\n",
    "\n",
    "# One unique thing we notice is a > icon on the part where\n",
    "# you click to go to the next page. It's an SVG with an \n",
    "# aria-label of \"Right arrow\"\n",
    "svg = soup.find(\"svg\", attrs={\"aria-label\": \"Right arrow\"})\n",
    "\n",
    "# That SVG is inside of a div\n",
    "svg_parent = svg.parent\n",
    "\n",
    "# And the tag right before that div (its \"previous sibling\")\n",
    "# is an anchor (link) tag with the path we need\n",
    "link = svg.parent.previousSibling\n",
    "\n",
    "# Then we can extract the path from that link to build the full URL\n",
    "relative_path = link.get(\"href\")\n",
    "next_page_url = \"https://web.archive.org\" + relative_path\n",
    "next_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in this function, to take in the current page's URL and return the\n",
    "# next page's URL\n",
    "def next_page(url):\n",
    "     # Get the content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Extract the relative path to build the full URL\n",
    "    svg = soup.find(\"svg\", attrs={\"aria-label\": \"Right arrow\"})\n",
    "    svg_parent = svg.parent\n",
    "    link = svg.parent.previousSibling\n",
    "    relative_path = link.get(\"href\")\n",
    "    next_page_url = \"https://web.archive.org\" + relative_path\n",
    "    return next_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://web.archive.org/web/20210326225933/https://ra.co/events/us/newyork?week=2019-04-06'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out your function\n",
    "next_page(EVENTS_PAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Next 500 Events\n",
    "\n",
    "In other words, repeatedly call `scrape_events` and `next_page` until you have assembled a dataframe with at least 500 rows.\n",
    "\n",
    "Display the data sorted by the number of attendees, greatest to least.\n",
    "\n",
    "We recommend adding a brief `time.sleep` call between `requests.get` calls to avoid rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Congratulations! In this lab, you successfully developed a pipeline to scrape a website for concert event information!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
